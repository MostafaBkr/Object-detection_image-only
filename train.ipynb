{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to TFRecord files\n",
    "train_tfrecord_paths = [\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/train/Mobile-Phones.tfrecord',\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/train/People.tfrecord',\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/train/glasses.tfrecord'\n",
    "]\n",
    "val_tfrecord_paths = [\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/val/Mobile-Phones.tfrecord',\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/val/People.tfrecord',\n",
    "    '/home/mostafabakr8962/Desktop/object_detection/tfrecord/val/glasses.tfrecord'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing function for TFRecord files including bounding boxes\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    \n",
    "    # Parse the example\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "    # Decode and preprocess the image\n",
    "    image = tf.io.decode_jpeg(example['image/encoded'], channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Handle bounding boxes: If there are no bounding boxes, return default values\n",
    "    xmin = tf.sparse.to_dense(example['image/object/bbox/xmin'], default_value=0.0)\n",
    "    ymin = tf.sparse.to_dense(example['image/object/bbox/ymin'], default_value=0.0)\n",
    "    xmax = tf.sparse.to_dense(example['image/object/bbox/xmax'], default_value=1.0)\n",
    "    ymax = tf.sparse.to_dense(example['image/object/bbox/ymax'], default_value=1.0)\n",
    "    \n",
    "    # Stack bounding boxes\n",
    "    bboxes = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "    \n",
    "    # Ensure bounding box has the right shape (num_boxes, 4)\n",
    "    tf.debugging.assert_rank(bboxes, 2, message=\"Bounding boxes should have rank 2\")\n",
    "\n",
    "    # Extract and process the label\n",
    "    label = tf.sparse.to_dense(example['image/object/class/label'], default_value=0)\n",
    "    \n",
    "    # Ensure that only one label is used for each image (e.g., choose the first if multiple labels exist)\n",
    "    label = tf.reduce_max(label)  # Choose the highest label for simplicity\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    num_classes = 4  # Set number of classes\n",
    "    labels_one_hot = tf.one_hot(tf.cast(label, tf.int32), depth=num_classes)\n",
    "\n",
    "    # Log shapes of bounding boxes and labels for debugging\n",
    "    tf.print(\"Image shape:\", tf.shape(image))\n",
    "    tf.print(\"Bounding boxes shape:\", tf.shape(bboxes))\n",
    "    tf.print(\"Labels shape:\", tf.shape(labels_one_hot))\n",
    "\n",
    "    return image, labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(tfrecord_dir_paths, batch_size, repeat=False):\n",
    "    # Get a list of all TFRecord files in the directories\n",
    "    tfrecord_paths = []\n",
    "    for dir_path in tfrecord_dir_paths:\n",
    "        tfrecord_paths.extend(glob.glob(dir_path + '/*.tfrecord'))\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_paths)\n",
    "    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()  # Cache data after loading once\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)  # Prefetch to optimize performance\n",
    "\n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Load the datasets\n",
    "train_dir_paths = ['/home/mostafabakr8962/Desktop/object_detection/tfrecord/train']\n",
    "val_dir_paths = ['/home/mostafabakr8962/Desktop/object_detection/tfrecord/val']\n",
    "\n",
    "batch_size = 16\n",
    "train_dataset = load_dataset(train_dir_paths, batch_size, repeat=True)\n",
    "val_dataset = load_dataset(val_dir_paths, batch_size, repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Build the model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with categorical crossentropy loss\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',  # Categorical crossentropy for multi-class classification\n",
    "    metrics=['accuracy', 'AUC']  # Add AUC metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m , restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_steps_per_epoch\u001b[39m(dataset):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5 , restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "def get_steps_per_epoch(dataset):\n",
    "    cardinality = tf.data.experimental.cardinality (dataset).numpy()\n",
    "    return cardinality if cardinality > 0 else 100  # Fallback value\n",
    "\n",
    "train_steps_per_epoch = get_steps_per_epoch(train_dataset)\n",
    "val_steps_per_epoch = get_steps_per_epoch(val_dataset)\n",
    "\n",
    "if train_steps_per_epoch > 0 and val_steps_per_epoch > 0:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=50,\n",
    "        validation_data=val_dataset,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        validation_steps=val_steps_per_epoch,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "    )\n",
    "else:\n",
    "    print(\"Error: One or both datasets are empty!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
